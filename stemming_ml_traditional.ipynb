{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CbKunh-i_P4"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPFyzHrVi_QG",
        "outputId": "af47d082-bf5b-4a94-df97-08c0e5c9025f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jln jatibarupolisi tdk bs gertak gubernur eman...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cewe lho kayak rasain sibuk jaga rasain sakit ...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kepingin gudeg mbarek bu hj amad foto google s...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jln jatibarubagian wilayah tn abangpengaturan ...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sharing alam aja kemarin jam 1800 batalin tike...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sekian thread baca thread aneh sih tulis sumpa...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sharing temen tuh emg bgt saat lu ngerasa lu b...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>orang pake ponco jas hujan pake kasur ya gara2...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>contoh yg gemar sudut teriak toleran tp gemar ...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>pulang udah h-4 lebaran dilema apa2 rumah leba...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet    label\n",
              "0  jln jatibarupolisi tdk bs gertak gubernur eman...    anger\n",
              "1  cewe lho kayak rasain sibuk jaga rasain sakit ...    anger\n",
              "2  kepingin gudeg mbarek bu hj amad foto google s...    happy\n",
              "3  jln jatibarubagian wilayah tn abangpengaturan ...    anger\n",
              "4  sharing alam aja kemarin jam 1800 batalin tike...    happy\n",
              "5  sekian thread baca thread aneh sih tulis sumpa...    anger\n",
              "6  sharing temen tuh emg bgt saat lu ngerasa lu b...    happy\n",
              "7  orang pake ponco jas hujan pake kasur ya gara2...  sadness\n",
              "8  contoh yg gemar sudut teriak toleran tp gemar ...    anger\n",
              "9  pulang udah h-4 lebaran dilema apa2 rumah leba...  sadness"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('datasets/dataset_stemming.csv')\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMvgcySyi_QI",
        "outputId": "e27ef085-e48f-4d3b-980d-6b0abc586c94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['anger', 'happy', 'sadness', 'love', 'fear'], dtype=object)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.label.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo17jeiui_QK"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4TY3zmki_QN",
        "outputId": "977293e1-4706-47d1-ea09-af63b32d69ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "82064\n"
          ]
        }
      ],
      "source": [
        "#preprocessing\n",
        "print(df['tweet'].apply(lambda x: len(x.split(' '))).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgfPzNuci_QQ"
      },
      "outputs": [],
      "source": [
        "special_character_remover = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "extra_symbol_remover = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yeSeb9fi_QR"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = special_character_remover.sub(' ', text)\n",
        "    text = extra_symbol_remover.sub('', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
        "    return text\n",
        "    \n",
        "df['tweet'] = df['tweet'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sWEdzeMi_QS",
        "outputId": "707a4c37-ba17-4d4c-d185-270efa48f204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78837\n"
          ]
        }
      ],
      "source": [
        "print(df['tweet'].apply(lambda x: len(x.split(' '))).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sLpW0e3i_QT"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df.tweet\n",
        "y = df.label\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNUbRmpWi_QU",
        "outputId": "2cb94232-0d5e-4e6f-8392-7b8936fc4d34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3501,), (876,), (3501,), (876,))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAZRmefzi_QU",
        "outputId": "6c0b9f05-f66e-4363-be12-954073d46712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy is : 0.6541095890410958\n"
          ]
        }
      ],
      "source": [
        "#logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "lr = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', LogisticRegression()),\n",
        "              ])\n",
        "\n",
        "lr.fit(X_train,y_train)\n",
        "y_pred1 = lr.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy is : {accuracy_score(y_pred1,y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOHdJpFgi_QV",
        "outputId": "1ee467a5-4585-467f-956b-e48c4e97393c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy 0.5958904109589042\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "\n",
        "naivebayes = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "naivebayes.fit(X_train, y_train)\n",
        "\n",
        "y_pred = naivebayes.predict(X_test)\n",
        "\n",
        "print(f'accuracy {accuracy_score(y_pred,y_test)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lKQJtiki_QV",
        "outputId": "27f316ed-5bed-4198-90a3-99ea1f1119c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19:59:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "accuracy 0.6015981735159818\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgboost = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', XGBClassifier()),\n",
        "              ])\n",
        "xgboost.fit(X_train, y_train)\n",
        "\n",
        "y_pred = xgboost.predict(X_test)\n",
        "\n",
        "print(f'accuracy {accuracy_score(y_pred,y_test)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwyI7jNzi_QW",
        "outputId": "1250d83a-ca26-472e-aca2-a54e0deaeb4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy 0.6221461187214612\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', SGDClassifier()),\n",
        "              ])\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "y_pred = sgd.predict(X_test)\n",
        "\n",
        "print(f'accuracy {accuracy_score(y_pred,y_test)}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "stemming_ml_traditional",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}